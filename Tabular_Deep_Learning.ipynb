{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71750177",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe0d55",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example features\n",
    "categorical_cols = ['machine_type', 'glue_type', 'wood_type']  # Update as needed\n",
    "numerical_cols = ['temperature', 'pressure', 'moisture', 'speed']  # Update as needed\n",
    "target_cols = ['accuracy', 'tensile_strength', 'waste_material']\n",
    "\n",
    "# Load your dataset here\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Scale numerical columns\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Split data\n",
    "X = df[categorical_cols + numerical_cols]\n",
    "y = df[target_cols]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Torch Dataset\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y, cat_cols, num_cols):\n",
    "        self.cat_data = torch.tensor(X[cat_cols].values, dtype=torch.long)\n",
    "        self.num_data = torch.tensor(X[num_cols].values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.cat_data[idx], self.num_data[idx], self.y[idx]\n",
    "\n",
    "train_ds = TabularDataset(X_train, y_train, categorical_cols, numerical_cols)\n",
    "val_ds = TabularDataset(X_val, y_val, categorical_cols, numerical_cols)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "# Neural Network\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, embedding_sizes, num_numerical, output_dim):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(categories, min(50, (categories + 1) // 2))\n",
    "            for categories, _ in embedding_sizes\n",
    "        ])\n",
    "        self.emb_drop = nn.Dropout(0.1)\n",
    "        emb_dim = sum([min(50, (categories + 1) // 2) for categories, _ in embedding_sizes])\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(emb_dim + num_numerical, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_cat, x_num):\n",
    "        x = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x = torch.cat([x, x_num], 1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Prepare embedding sizes\n",
    "embedding_sizes = [(df[col].nunique(), 1) for col in categorical_cols]\n",
    "model = TabularModel(embedding_sizes, num_numerical=len(numerical_cols), output_dim=len(target_cols))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5adebeb",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x_cat, x_num, y in train_loader:\n",
    "            x_cat, x_num, y = x_cat.to(device), x_num.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_cat, x_num)\n",
    "            loss = loss_fn(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb6174e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_true, y_pred = [], []\n",
    "    for x_cat, x_num, y in val_loader:\n",
    "        x_cat, x_num = x_cat.to(device), x_num.to(device)\n",
    "        outputs = model(x_cat, x_num)\n",
    "        y_true.append(y)\n",
    "        y_pred.append(outputs.cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    y_pred = torch.cat(y_pred, 0).numpy()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "for i, col in enumerate(target_cols):\n",
    "    rmse = mean_squared_error(y_true[:, i], y_pred[:, i], squared=False)\n",
    "    r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "    print(f\"{col.upper()} - RMSE: {rmse:.3f}, R2: {r2:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
